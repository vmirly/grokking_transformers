{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam Classification\n",
    "\n",
    "In this notebook, we will explore the Spam Classification dataset from the UCI Machine Learning Repository. Our goal is to build a neural network to classify emails as spam or not spam.\n",
    "\n",
    "To begin, we will implement a simple Perceptron model to demonstrate its limitations on this dataset. Since the Perceptron cannot handle non-linearly separable data, we will then transition to a more powerful neural network model that can effectively classify the emails.\n",
    "\n",
    "Let's get started! ðŸš€\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/228/sms+spam+collection\n",
    "\n",
    "```bash\n",
    "wget https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\n",
    "\n",
    "unzip sms+spam+collection.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of spam messages:  747\n",
      "Number of ham messages:  4827\n",
      "Total number of messages:  5574\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "spam, ham = [], []\n",
    "with open(\"SMSSpamCollection\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        label, text = line.split(\"\\t\")\n",
    "        if label.startswith(\"spam\"):\n",
    "            spam.append(text)\n",
    "        else:\n",
    "            ham.append(text)\n",
    "        data.append((text, label))\n",
    "\n",
    "print(\"Number of spam messages: \", len(spam))\n",
    "print(\"Number of ham messages: \", len(ham))\n",
    "print(\"Total number of messages: \", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering: Designing Our Features\n",
    "\n",
    "Now, we need to design our features to effectively classify messages as spam or ham. For this dataset, we have manually selected a set of keywords that are commonly associated with spam and another set of keywords that frequently appear in ham (non-spam) messages.\n",
    "\n",
    "Our features are defined as the count of these spam-related and ham-related words that occur in each text message. By using these word counts as input features, we aim to capture key patterns that distinguish spam from legitimate messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  2\n",
      "Number of samples:  5574\n",
      "Shape of features:  (5574, 2)\n",
      "Shape of labels:  (5574,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# using domain knowledge\n",
    "# list of typical spam words (domain knowledge)\n",
    "spam_words = set([\n",
    "    \"free\", \"credit\", \"loan\", \"cash\",\n",
    "    \"money\", \"urgent\", \"sale\", \"offer\",\n",
    "    \"discount\", \"save\", \"clearance\", \"win\",\n",
    "    \"winner\", \"prize\", \"bonus\", \"gift\",\n",
    "    \"click\", \"visit\", \"limited\", \"today\",\n",
    "    \"now\", \"apply\", \"easy\", \"fast\",\n",
    "    \"quick\", \"double\", \"triple\", \"guarantee\"\n",
    "])\n",
    "\n",
    "# list of typical ham words (domain knowledge)\n",
    "ham_words = set([\n",
    "    \"meeting\", \"lunch\", \"dinner\", \"home\",\n",
    "    \"office\", \"work\", \"project\", \"report\",\n",
    "    \"email\", \"phone\", \"call\", \"meeting\",\n",
    "    \"party\", \"movie\", \"game\", \"play\",\n",
    "    \"music\", \"dance\", \"book\", \"read\",\n",
    "    \"write\", \"paint\", \"draw\", \"travel\",\n",
    "    \"trip\", \"visit\", \"family\", \"friend\"\n",
    "])\n",
    "\n",
    "# generate features based on the domain knowledge\n",
    "# feature-1: count of the spam knowledge words\n",
    "# feature-2: count of the ham knowledge words\n",
    "features, labels = [], []\n",
    "for text, label in data:\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    x = [0, 0]\n",
    "    for w in words:\n",
    "        if w in spam_words:\n",
    "            x[0] += 1\n",
    "        if w in ham_words:\n",
    "            x[1] += 1\n",
    "    features.append(x)\n",
    "    labels.append(label)\n",
    "\n",
    "print(\"Number of features: \", len(features[0]))\n",
    "print(\"Number of samples: \", len(features))\n",
    "\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "print(\"Shape of features: \", features.shape)\n",
    "print(\"Shape of labels: \", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
